{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "QxJmT6twL-_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1JBvFk7L4sr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Imports libraries for data handling, embedding generation, FAISS-based similarity search,\n",
        "and neural network computations.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import faiss\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load BioBERT model\n"
      ],
      "metadata": {
        "id": "rouCUFr-MDR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loads the BioBERT model and tokenizer for generating embeddings from biomedical texts.\n",
        "The model used is 'dmis-lab/biobert-base-cased-v1.1'.\n",
        "\"\"\"\n",
        "print(\"Loading BioBERT model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\").to(\"cuda\")  # Move model to GPU\n",
        "print(\"BioBERT loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "DUqKI7_CMBQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate embeddings and initialize FAISS\n"
      ],
      "metadata": {
        "id": "loTAUYlzMHi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generates embeddings for a list of contexts and initializes a FAISS index for similarity search.\n",
        "\n",
        "Args:\n",
        "    contexts (list): List of context strings to generate embeddings for.\n",
        "    batch_size (int, optional): Number of contexts to process in each batch. Defaults to 16.\n",
        "\n",
        "Returns:\n",
        "    tuple: FAISS index and a list of embeddings.\n",
        "\"\"\"\n",
        "def initialize_faiss_with_embeddings(contexts, batch_size=16):\n",
        "    print(\"Generating embeddings and initializing FAISS index...\")\n",
        "    dimension = 768  # BioBERT CLS token dimension\n",
        "    index = faiss.IndexFlatIP(dimension)  # Inner-product for similarity\n",
        "\n",
        "    embeddings = []\n",
        "    for i in range(0, len(contexts), batch_size):\n",
        "        batch_texts = contexts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            outputs = biobert_model(**inputs)\n",
        "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS token embeddings\n",
        "        index.add(batch_embeddings)\n",
        "        embeddings.append(batch_embeddings)\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return index, embeddings\n"
      ],
      "metadata": {
        "id": "qrw7WcpJME1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets\n"
      ],
      "metadata": {
        "id": "SKCmDDbSMTuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loads the MedQA-USMLE, Medical Meadow, and PubMedQA datasets, and combines their contexts.\n",
        "\n",
        "Returns:\n",
        "    tuple: DataFrame for MedQA and a combined list of contexts.\n",
        "\"\"\"\n",
        "def load_datasets():\n",
        "    medqa_path = \"NLP_Project/Preprocessed/medqa_usmle_preprocessed.csv\"\n",
        "    medical_meadow_path = \"NLP_Project/Preprocessed/medical_meadow_preprocessed.csv\"\n",
        "    pubmedqa_path = \"NLP_Project/Preprocessed/pubmedqa_preprocessed.json\"\n",
        "\n",
        "    medqa_df = pd.read_csv(medqa_path).head(100)  # Load a subset for testing\n",
        "    medical_meadow_df = pd.read_csv(medical_meadow_path)\n",
        "    with open(pubmedqa_path, \"r\") as f:\n",
        "        pubmedqa_data = json.load(f)\n",
        "\n",
        "    medical_meadow_contexts = medical_meadow_df['output'].tolist()\n",
        "    pubmedqa_contexts = [context for entry in pubmedqa_data.values() for context in entry.get('CONTEXTS', [])]\n",
        "\n",
        "    combined_contexts = medical_meadow_contexts + pubmedqa_contexts\n",
        "    print(f\"Total contexts: {len(combined_contexts)}\")\n",
        "    return medqa_df, combined_contexts\n"
      ],
      "metadata": {
        "id": "eoLT_VkcMJjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid retrieval function\n"
      ],
      "metadata": {
        "id": "MGc01cPNMYbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Retrieves the top-k most relevant contexts for each option using FAISS.\n",
        "\n",
        "Args:\n",
        "    question (str): Question text.\n",
        "    options (dict): Dictionary of options (e.g., {\"A\": \"Option A text\", ...}).\n",
        "    faiss_index (faiss.Index): Prebuilt FAISS index for similarity search.\n",
        "    combined_contexts (list): List of context strings.\n",
        "    top_k (int, optional): Number of top contexts to retrieve. Defaults to 3.\n",
        "    token_limit (int, optional): Maximum token length for retrieved contexts. Defaults to 700.\n",
        "\n",
        "Returns:\n",
        "    dict: Retrieved contexts with similarity scores for each option.\n",
        "\"\"\"\n",
        "# used copilot for refernce\n",
        "def retrieve_contexts_with_faiss(question, options, faiss_index, combined_contexts, top_k=3, token_limit=700):\n",
        "    retrieved_contexts = {}\n",
        "\n",
        "    for option_key, option_text in options.items():\n",
        "        query = f\"{question} {option_text}\"\n",
        "\n",
        "        # Generate query embedding\n",
        "        inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            query_embedding = biobert_model(**inputs).last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "        # FAISS search\n",
        "        distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "\n",
        "        # Retrieve contexts with token limit and similarity score\n",
        "        retrieved_contexts[option_key] = []\n",
        "        for idx, dist in zip(indices[0], distances[0]):\n",
        "            context = \" \".join(combined_contexts[idx].split()[:token_limit])\n",
        "            retrieved_contexts[option_key].append({\"context\": context, \"similarity_score\": dist})\n",
        "\n",
        "    return retrieved_contexts\n"
      ],
      "metadata": {
        "id": "uESEuYO5MW2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process questions\n"
      ],
      "metadata": {
        "id": "Bb7-XxeYMdhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Processes each question in the MedQA dataset and retrieves contexts for each option.\n",
        "\n",
        "Args:\n",
        "    medqa_df (pd.DataFrame): DataFrame containing MedQA questions and options.\n",
        "    faiss_index (faiss.Index): Prebuilt FAISS index for similarity search.\n",
        "    combined_contexts (list): List of context strings.\n",
        "\n",
        "Returns:\n",
        "    list: Results containing questions, options, retrieved contexts, and similarity scores.\n",
        "\"\"\"\n",
        "def process_questions(medqa_df, faiss_index, combined_contexts):\n",
        "    results = []\n",
        "    for idx, row in medqa_df.iterrows():\n",
        "        question = row['question']\n",
        "        options = eval(row['options'])\n",
        "        print(f\"Processing Question {idx+1}: {question}\")\n",
        "        retrieved_contexts = retrieve_contexts_with_faiss(question, options, faiss_index, combined_contexts)\n",
        "        result_row = {\n",
        "            \"question\": question,\n",
        "            \"option_a\": options.get(\"A\", \"\"),\n",
        "            \"context_a\": retrieved_contexts.get(\"A\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"context\"],\n",
        "            \"similarity_a\": retrieved_contexts.get(\"A\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"similarity_score\"],\n",
        "            \"option_b\": options.get(\"B\", \"\"),\n",
        "            \"context_b\": retrieved_contexts.get(\"B\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"context\"],\n",
        "            \"similarity_b\": retrieved_contexts.get(\"B\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"similarity_score\"],\n",
        "            \"option_c\": options.get(\"C\", \"\"),\n",
        "            \"context_c\": retrieved_contexts.get(\"C\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"context\"],\n",
        "            \"similarity_c\": retrieved_contexts.get(\"C\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"similarity_score\"],\n",
        "            \"option_d\": options.get(\"D\", \"\"),\n",
        "            \"context_d\": retrieved_contexts.get(\"D\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"context\"],\n",
        "            \"similarity_d\": retrieved_contexts.get(\"D\", [{\"context\": \"No relevant context found.\", \"similarity_score\": 0}])[0][\"similarity_score\"],\n",
        "        }\n",
        "        results.append(result_row)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "QlX-bIRuMcB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save results\n"
      ],
      "metadata": {
        "id": "Z0g86J1OMhuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Saves the retrieved results to a CSV file.\n",
        "\n",
        "Args:\n",
        "    results (list): List of results containing questions, options, contexts, and similarity scores.\n",
        "    output_path (str, optional): File path to save the results. Defaults to 'NLP_Project/Preprocessed/HY_bio_faiss1.csv'.\n",
        "\"\"\"\n",
        "def save_results(results, output_path=\"NLP_Project/Preprocessed/HY_bio_faiss1.csv\"):\n",
        "    pd.DataFrame(results).to_csv(output_path, index=False)\n",
        "    print(f\"Results saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "-cylegv3Mghv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main workflow"
      ],
      "metadata": {
        "id": "x0cwD6xMMnDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Main script to load datasets, initialize FAISS index with BioBERT embeddings,\n",
        "process questions, and save results.\n",
        "\"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "    # Load datasets\n",
        "    medqa_df, combined_contexts = load_datasets()\n",
        "\n",
        "    # Initialize FAISS and generate BioBERT embeddings\n",
        "    faiss_index, _ = initialize_faiss_with_embeddings(combined_contexts)\n",
        "\n",
        "    # Process questions and retrieve contexts\n",
        "    results = process_questions(medqa_df, faiss_index, combined_contexts)\n",
        "\n",
        "    # Save the results\n",
        "    save_results(results)\n"
      ],
      "metadata": {
        "id": "k2GyoIpyMkLG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}