{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### For the refence and knowlage used chatgpt(mostly for docs string) and guru99"
      ],
      "metadata": {
        "id": "TsiRCc5cKqOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries\n"
      ],
      "metadata": {
        "id": "bOy91WUXKA8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4BXU1FZJ_ht"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Imports required libraries for data processing, visualization, embeddings generation, and similarity calculations.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sentence_transformers import util\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from wordcloud import WordCloud\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load BioBERT model\n"
      ],
      "metadata": {
        "id": "KmofUAJWKGam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loads the BioBERT model for generating contextual embeddings from biomedical texts.\n",
        "The model used is 'dmis-lab/biobert-base-cased-v1.1'.\n",
        "\"\"\"\n",
        "print(\"Loading BioBERT model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\").to(\"cuda\")  # Move model to GPU\n",
        "print(\"BioBERT loaded successfully!\")\n"
      ],
      "metadata": {
        "id": "3PAVldL2KDdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function to generate embeddings in batches\n"
      ],
      "metadata": {
        "id": "AW3x6U4aKLbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generates embeddings for a list of texts in batches using BioBERT.\n",
        "\n",
        "Args:\n",
        "    texts (list): List of input texts to generate embeddings for.\n",
        "    batch_size (int, optional): Number of texts to process in each batch. Defaults to 16.\n",
        "\n",
        "Returns:\n",
        "    torch.Tensor: Tensor of embeddings for the input texts.\n",
        "\"\"\"\n",
        "# used cpt as well as some research paper for understand\n",
        "def get_biobert_embeddings_in_batches(texts, batch_size=16):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            outputs = biobert_model(**inputs)\n",
        "        embeddings.append(outputs.last_hidden_state[:, 0, :].cpu())  # Use CLS token embeddings\n",
        "        torch.cuda.empty_cache()  # Clear GPU memory\n",
        "    return torch.cat(embeddings, dim=0)\n"
      ],
      "metadata": {
        "id": "3tH4tsyxKIwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load datasets\n"
      ],
      "metadata": {
        "id": "fMh-kZSwKR2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loads preprocessed datasets: MedQA-USMLE, Medical Meadow, and PubMedQA.\n",
        "Combines all contexts for further processing.\n",
        "\"\"\"\n",
        "medqa_path = \"NLP_Project/Preprocessed/medqa_usmle_preprocessed.csv\"\n",
        "medqa_df = pd.read_csv(medqa_path).head(100)  # Load a subset for testing\n",
        "\n",
        "medical_meadow_path = \"NLP_Project/Preprocessed/medical_meadow_preprocessed.csv\"\n",
        "medical_meadow_df = pd.read_csv(medical_meadow_path)\n",
        "medical_meadow_contexts = medical_meadow_df['output'].tolist()\n",
        "\n",
        "pubmedqa_path = \"NLP_Project/Preprocessed/pubmedqa_preprocessed.json\"\n",
        "with open(pubmedqa_path, \"r\") as f:\n",
        "    pubmedqa_data = json.load(f)\n",
        "pubmedqa_contexts = [context for entry in pubmedqa_data.values() for context in entry.get('CONTEXTS', [])]\n",
        "\n",
        "# Combine contexts\n",
        "combined_contexts = medical_meadow_contexts + pubmedqa_contexts\n",
        "print(\"Total contexts:\", len(combined_contexts))\n"
      ],
      "metadata": {
        "id": "E9GxUUgqKOPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate context embeddings\n"
      ],
      "metadata": {
        "id": "i5LNDfhoKWLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Generate context embeddings\n",
        "\"\"\"\n",
        "Generates embeddings for the combined contexts using BioBERT in batches.\n",
        "\"\"\"\n",
        "print(\"Generating context embeddings in batches...\")\n",
        "context_embeddings = get_biobert_embeddings_in_batches(combined_contexts, batch_size=16)\n",
        "print(\"Context embeddings generated successfully!\")\n"
      ],
      "metadata": {
        "id": "fFSUhKFoKTnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function to retrieve relevant contexts\n"
      ],
      "metadata": {
        "id": "aV6KwoECKdpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Retrieves the most relevant context for each option using BioBERT.\n",
        "\n",
        "Args:\n",
        "    question (str): The main question text.\n",
        "    options (dict): Dictionary of options (e.g., {\"A\": \"Option A text\", ...}).\n",
        "    token_limit (int, optional): Maximum number of tokens in retrieved contexts. Defaults to 700.\n",
        "\n",
        "Returns:\n",
        "    tuple: A dictionary of retrieved contexts and a dictionary of similarity scores.\n",
        "\"\"\"\n",
        "def retrieve_contexts_with_biobert(question, options, token_limit=700): # guru99 for cpu error\n",
        "    retrieved_contexts = {}\n",
        "    similarity_scores = {}\n",
        "    for option_key, option_text in options.items():\n",
        "        query = f\"{question} {option_text}\"\n",
        "        inputs = tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "        with torch.no_grad():\n",
        "            query_embedding = biobert_model(**inputs).last_hidden_state[:, 0, :].cpu()\n",
        "\n",
        "        # Compute similarity\n",
        "        similarity_scores_batch = torch.nn.functional.cosine_similarity(query_embedding, context_embeddings, dim=1)\n",
        "        top_index = torch.argmax(similarity_scores_batch).item()\n",
        "        context = combined_contexts[top_index]\n",
        "        truncated_context = ' '.join(context.split()[:token_limit])  # Limit to token_limit tokens\n",
        "        retrieved_contexts[option_key] = truncated_context\n",
        "        similarity_scores[option_key] = similarity_scores_batch[top_index].item()  # Store the similarity score\n",
        "        torch.cuda.empty_cache()  # Clear GPU memory\n",
        "    return retrieved_contexts, similarity_scores\n"
      ],
      "metadata": {
        "id": "854MDcPfKbu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process questions and retrieve contexts\n"
      ],
      "metadata": {
        "id": "THz9FsSLKiWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Processes each question from the MedQA dataset, retrieves relevant contexts\n",
        "for each option, and stores the results in a structured format.\n",
        "\"\"\"\n",
        "results = []\n",
        "for idx, row in medqa_df.iterrows():\n",
        "    question = row['question']\n",
        "    options = eval(row['options'])\n",
        "    print(f\"Processing Question {idx+1}: {question}\")\n",
        "    retrieved_contexts, similarity_scores = retrieve_contexts_with_biobert(question, options)\n",
        "    # used gpt for proper prinnt with formation\n",
        "    result_row = {\n",
        "        \"question\": question,\n",
        "        \"option_a\": options.get(\"A\", \"\"),\n",
        "        \"context_a\": retrieved_contexts.get(\"A\", \"No relevant context found.\"),\n",
        "        \"similarity_a\": similarity_scores.get(\"A\", 0),\n",
        "        \"option_b\": options.get(\"B\", \"\"),\n",
        "        \"context_b\": retrieved_contexts.get(\"B\", \"No relevant context found.\"),\n",
        "        \"similarity_b\": similarity_scores.get(\"B\", 0),\n",
        "        \"option_c\": options.get(\"C\", \"\"),\n",
        "        \"context_c\": retrieved_contexts.get(\"C\", \"No relevant context found.\"),\n",
        "        \"similarity_c\": similarity_scores.get(\"C\", 0),\n",
        "        \"option_d\": options.get(\"D\", \"\"),\n",
        "        \"context_d\": retrieved_contexts.get(\"D\", \"No relevant context found.\"),\n",
        "        \"similarity_d\": similarity_scores.get(\"D\", 0),\n",
        "    }\n",
        "    results.append(result_row)\n"
      ],
      "metadata": {
        "id": "o6Lay5RGKg2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save results to CSV\n"
      ],
      "metadata": {
        "id": "oL9SGRf1KnfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Saves the retrieved contexts and similarity scores to a CSV file for further analysis.\n",
        "\n",
        "Output:\n",
        "    CSV file containing questions, options, contexts, and similarity scores.\n",
        "\"\"\"\n",
        "output_path = \"NLP_Project/Retrieved/TRY/Biobert1.csv\"\n",
        "pd.DataFrame(results).to_csv(output_path, index=False)\n",
        "print(f\"Results saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "JPtTHd9dKmCd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}